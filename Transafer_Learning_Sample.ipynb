{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c13c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.0220 - Accuracy: 69.68%\n",
      "Epoch 2/10 - Loss: 0.0166 - Accuracy: 77.51%\n",
      "Epoch 3/10 - Loss: 0.0149 - Accuracy: 79.24%\n",
      "Epoch 4/10 - Loss: 0.0139 - Accuracy: 81.32%\n",
      "Epoch 5/10 - Loss: 0.0160 - Accuracy: 79.73%\n",
      "Epoch 6/10 - Loss: 0.0132 - Accuracy: 82.53%\n",
      "Epoch 7/10 - Loss: 0.0133 - Accuracy: 82.61%\n",
      "Epoch 8/10 - Loss: 0.0138 - Accuracy: 81.79%\n",
      "Epoch 9/10 - Loss: 0.0130 - Accuracy: 82.11%\n",
      "Epoch 10/10 - Loss: 0.0129 - Accuracy: 83.48%\n",
      "Test Loss: 0.0109 - Test Accuracy: 85.10%\n",
      "Test Weighted Precision: 0.8564 - Test Weighted Recall: 0.8510 - Test Weighted F1 Score: 0.8506 - Test Weighted AUC: 0.9739\n",
      "Test Macro Precision: 0.8631 - Test Macro Recall: 0.8361 - Test Macro F1 Score: 0.8457 - Test Macro AUC: 0.9761\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the labeled dataset\n",
    "dataset = ImageFolder(root='C:/Users/sevmou2300/Desktop/Home/Postdoc/Task1_Plant_categorisation/Plantvation+Holmen-Spring23/Top camera/ResizedImages', transform=transform)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create the pre-trained MobileNetV2 model and modify it as a feature extractor\n",
    "num_classes = len(dataset.classes)\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the MobileNetV2 model so they are not updated during training\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last fully connected layer with a new one that has the correct number of output classes\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.last_channel, num_classes)\n",
    "model = mobilenet.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "# Create some empty arrays to store logs \n",
    "loss_log = []\n",
    "accuracy_log = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += torch.sum(predictions == labels).item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy = 100.0 * train_correct / len(train_loader.dataset)\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f} - Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Store training stats after each epoch\n",
    "    loss_log.append(train_loss)\n",
    "    accuracy_log.append(train_accuracy)\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "\n",
    "test_probabilities = []  # Store predicted probabilities instead of class labels\n",
    "test_labels_list = []\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_correct += torch.sum(predictions == labels).item()\n",
    "\n",
    "        test_probabilities.extend(probabilities.cpu().tolist())  # Store probabilities\n",
    "        test_labels_list.extend(labels.cpu().tolist())\n",
    "        test_predictions.extend(predictions.cpu().tolist())  # Store predictions\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_accuracy = 100.0 * test_correct / len(test_loader.dataset)\n",
    "\n",
    "# Convert the test_probabilities and test_labels_list to numpy arrays\n",
    "test_probabilities = np.array(test_probabilities)\n",
    "test_labels_array = np.array(test_labels_list)\n",
    "\n",
    "# Calculate testing metrics\n",
    "test_precision_weighted = precision_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_recall_weighted = recall_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_f1_weighted = f1_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_auc_weighted = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='weighted')\n",
    "\n",
    "test_precision_macro = precision_score(test_labels_array, test_predictions, average='macro')\n",
    "test_recall_macro = recall_score(test_labels_array, test_predictions, average='macro')\n",
    "test_f1_macro = f1_score(test_labels_array, test_predictions, average='macro')\n",
    "test_auc_macro = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='macro')\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test Weighted Precision: {test_precision_weighted:.4f} - Test Weighted Recall: {test_recall_weighted:.4f} - Test Weighted F1 Score: {test_f1_weighted:.4f} - Test Weighted AUC: {test_auc_weighted:.4f}\")\n",
    "print(f\"Test Macro Precision: {test_precision_macro:.4f} - Test Macro Recall: {test_recall_macro:.4f} - Test Macro F1 Score: {test_f1_macro:.4f} - Test Macro AUC: {test_auc_macro:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"TL_MobileNetV2_Top.pth\")\n",
    "\n",
    "\n",
    "# Save the results to an Excel file\n",
    "results_dict = {\n",
    "    'Test Loss': [test_loss],\n",
    "    'Test Accuracy': [test_accuracy],\n",
    "    'Test Weighted Precision': [test_precision_weighted],\n",
    "    'Test Weighted Recall': [test_recall_weighted],\n",
    "    'Test Weighted F1 Score': [test_f1_weighted],\n",
    "    'Test Weighted AUC': [test_auc_weighted],\n",
    "    'Test Macro Precision': [test_precision_macro],\n",
    "    'Test Macro Recall': [test_recall_macro],\n",
    "    'Test Macro F1 Score': [test_f1_macro],\n",
    "    'Test Macro AUC': [test_auc_macro],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_excel(\"TL_MobileNetV2_Top.xlsx\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea640f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0118 - Test Accuracy: 84.75%\n",
      "Test Weighted Precision: 0.8474 - Test Weighted Recall: 0.8475 - Test Weighted F1 Score: 0.8474 - Test Weighted AUC: 0.9689\n",
      "Test Macro Precision: 0.8471 - Test Macro Recall: 0.8441 - Test Macro F1 Score: 0.8455 - Test Macro AUC: 0.9708\n"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "import numpy as np\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "test_probabilities = []  # Store predicted probabilities instead of class labels\n",
    "test_labels_list = []\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_correct += torch.sum(predictions == labels).item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "        test_probabilities.extend(probabilities.cpu().tolist())  # Store probabilities\n",
    "        test_labels_list.extend(labels.cpu().tolist())\n",
    "        test_predictions.extend(predictions.cpu().tolist())  # Store predictions\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_accuracy = 100.0 * test_correct / test_total\n",
    "\n",
    "# Convert the test_probabilities and test_labels_list to numpy arrays\n",
    "test_probabilities = np.array(test_probabilities)\n",
    "test_labels_array = np.array(test_labels_list)\n",
    "\n",
    "# Calculate testing metrics\n",
    "test_precision_weighted = precision_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_recall_weighted = recall_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_f1_weighted = f1_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_auc_weighted = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='weighted')\n",
    "\n",
    "test_precision_macro = precision_score(test_labels_array, test_predictions, average='macro')\n",
    "test_recall_macro = recall_score(test_labels_array, test_predictions, average='macro')\n",
    "test_f1_macro = f1_score(test_labels_array, test_predictions, average='macro')\n",
    "test_auc_macro = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='macro')\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test Weighted Precision: {test_precision_weighted:.4f} - Test Weighted Recall: {test_recall_weighted:.4f} - Test Weighted F1 Score: {test_f1_weighted:.4f} - Test Weighted AUC: {test_auc_weighted:.4f}\")\n",
    "print(f\"Test Macro Precision: {test_precision_macro:.4f} - Test Macro Recall: {test_recall_macro:.4f} - Test Macro F1 Score: {test_f1_macro:.4f} - Test Macro AUC: {test_auc_macro:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model_train_test_split.pth\")\n",
    "\n",
    "# Save the results to an Excel file\n",
    "results_dict = {\n",
    "    'Test Loss': [test_loss],\n",
    "    'Test Accuracy': [test_accuracy],\n",
    "    'Test Weighted Precision': [test_precision_weighted],\n",
    "    'Test Weighted Recall': [test_recall_weighted],\n",
    "    'Test Weighted F1 Score': [test_f1_weighted],\n",
    "    'Test Weighted AUC': [test_auc_weighted],\n",
    "    'Test Macro Precision': [test_precision_macro],\n",
    "    'Test Macro Recall': [test_recall_macro],\n",
    "    'Test Macro F1 Score': [test_f1_macro],\n",
    "    'Test Macro AUC': [test_auc_macro],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_excel(\"TL_Resnet18_.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf7d371-81df-43bf-bbea-9c986bbc2770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c5fbc-fd9d-49a6-b00a-cb7eb2cd2b6a",
   "metadata": {},
   "source": [
    "**New Criteria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae464fea-c927-4c25-ac17-665fe413fa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_folder = ImageFolder(root=root, transform=transform)\n",
    "        self.classes = self.image_folder.classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_folder[idx]\n",
    "        filename = os.path.basename(self.image_folder.imgs[idx][0])\n",
    "        \n",
    "        return {'image': image, 'label': label, 'filename': filename}\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the labeled dataset using CustomDataset\n",
    "dataset = CustomDataset(root='C:/Users/sevmou2300/Desktop/Home/Postdoc/Task1_Plant_categorisation/Plantvation+Holmen-Spring23/Top camera/ResizedImages', transform=transform)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_size = int(0.2 * len(dataset))  # Adjust the split ratio as needed\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create the pre-trained SqueezeNet model and modify it as a feature extractor\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the MobileNetV2 model so they are not updated during training\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last fully connected layer with a new one that has the correct number of output classes\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.last_channel, num_classes)\n",
    "model = mobilenet.to(device)\n",
    "\n",
    "\n",
    "# Load the state dictionary of the saved model\n",
    "state_dict = torch.load(\"TL_MobileNetV2_Top.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b996289e-6896-4cf8-a44e-e57a218f2d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                    [-1, 4]           5,124\n",
      "================================================================\n",
      "Total params: 2,228,996\n",
      "Trainable params: 5,124\n",
      "Non-trainable params: 2,223,872\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.86\n",
      "Params size (MB): 8.50\n",
      "Estimated Total Size (MB): 161.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46876e9-3330-4143-ac40-1ec0128907bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0105 - Test Accuracy: 0.86%\n",
      "Test Weighted Precision: 0.8641 - Test Weighted Recall: 0.8589 - Test Weighted F1 Score: 0.8583 - Test Weighted AUC: 0.9761\n",
      "Test Macro Precision: 0.8706 - Test Macro Recall: 0.8430 - Test Macro F1 Score: 0.8528 - Test Macro AUC: 0.9782\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Testing phase\n",
    "import numpy as np\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "test_probabilities = []  # Store predicted probabilities instead of class labels\n",
    "test_labels_list = []\n",
    "\n",
    "test_predictions = []\n",
    "test_filenames = []  # List to store filenames\n",
    "\n",
    "# Load your Excel files and extract date information into a dictionary\n",
    "# Replace 'path_to_excel_folder' with the actual path to your Excel files\n",
    "excel_files = ['class_0.xlsx', 'class_1.xlsx', 'class_2.xlsx', 'class_3.xlsx']\n",
    "date_info = {}\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to calculate the time difference between two timestamps\n",
    "def calculate_time_difference(time1, time2):\n",
    "    datetime_format = \"%Y:%m:%d %H:%M:%S\"\n",
    "    t1 = datetime.strptime(time1, datetime_format)\n",
    "    t2 = datetime.strptime(time2, datetime_format)\n",
    "    time_diff = abs((t1 - t2).total_seconds())  # Time difference in seconds\n",
    "    return time_diff\n",
    "\n",
    "# Assuming you have a function to load the creation date from the Excel file\n",
    "def load_creation_date(image_title, excel_file):\n",
    "    try:\n",
    "        # Load the Excel file into a DataFrame\n",
    "        df = pd.read_excel(excel_file)\n",
    "\n",
    "        # Assuming the DataFrame has columns 'Image Title' and 'Creation Date'\n",
    "        if 'Image Title' in df.columns and 'Creation Date' in df.columns:\n",
    "            # Find the row where 'Image Title' matches the given image_title\n",
    "            row = df[df['Image Title'] == image_title]\n",
    "\n",
    "            # Check if a matching row was found\n",
    "            if not row.empty:\n",
    "                # Extract the creation date from the matching row\n",
    "                creation_date = row.iloc[0]['Creation Date']\n",
    "\n",
    "                # Ensure that the creation date is a string\n",
    "                if isinstance(creation_date, str):\n",
    "                    return creation_date\n",
    "\n",
    "        # If the image title was not found or the date is not a string, return None\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading creation date for '{image_title}' from '{excel_file}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "time_boundaries = [\n",
    "    \"2023:05:16 00:00:00\",  # t0\n",
    "    \"2023:05:27 21:13:46\",  # t1\n",
    "    \"2023:06:08 12:03:15\",  # t2\n",
    "    \"2023:06:20 13:51:00\",  # t3\n",
    "    \"2023:06:29 14:32:00\"   # t4\n",
    "]\n",
    "\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_correct_time_dependent = 0  # Counter for time-dependent correct predictions\n",
    "test_total = 0\n",
    " # Initialize total penalty\n",
    "total_penalty = 0\n",
    "ATBD_Todal = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        filenames = batch['filename']\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_correct += torch.sum(predictions == labels).item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "        test_probabilities.extend(probabilities.cpu().tolist())\n",
    "        test_labels_list.extend(labels.cpu().tolist())\n",
    "        test_predictions.extend(predictions.cpu().tolist())\n",
    "        test_filenames.extend(filenames)\n",
    "        \n",
    "        # Constants\n",
    "        THRESHOLD = 21600\n",
    "\n",
    "       \n",
    "        for i in range(len(filenames)):\n",
    "            true_class = labels[i].item()\n",
    "            predicted_class = predictions[i].item()\n",
    "            image_title = filenames[i]\n",
    "    \n",
    "            # Check if true class equals predicted class\n",
    "            if true_class == predicted_class:\n",
    "                penalty = 1  # Set penalty to 0\n",
    "                ATBD_Sample = 0  # Set ATBD_Sample to 0\n",
    "            else:\n",
    "                # Load creation date and calculate time differences\n",
    "                creation_date = load_creation_date(image_title, excel_files[true_class])\n",
    "                lower_bound = time_boundaries[predicted_class]\n",
    "                upper_bound = time_boundaries[predicted_class + 1]\n",
    "                time_diff_lower = calculate_time_difference(creation_date, lower_bound)\n",
    "                time_diff_upper = calculate_time_difference(creation_date, upper_bound)\n",
    "        \n",
    "                # Calculate closeness\n",
    "                time_difference = min(time_diff_lower, time_diff_upper)\n",
    "        \n",
    "                # Calculate penalty\n",
    "                if time_difference <= THRESHOLD:\n",
    "                    penalty = time_difference / THRESHOLD\n",
    "                else:\n",
    "                    penalty = 0\n",
    "        \n",
    "                # Calculate ATBD_Sample\n",
    "                ATBD_Sample = max(0, time_difference - THRESHOLD)\n",
    "    \n",
    "            # Accumulate penalties\n",
    "            total_penalty += penalty\n",
    "            # Calculate ATBD_Todal (total penalty)\n",
    "            ATBD_Todal += ATBD_Sample\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the time-dependent accuracy\n",
    "time_dependent_accuracy = total_penalty / test_total\n",
    "ATBD_Normalise=ATBD_Todal/test_total\n",
    "\n",
    "# Calculate the regular accuracy\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# Convert the test_probabilities and test_labels_list to numpy arrays\n",
    "test_probabilities = np.array(test_probabilities)\n",
    "test_labels_array = np.array(test_labels_list)\n",
    "\n",
    "# Calculate testing metrics\n",
    "test_precision_weighted = precision_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_recall_weighted = recall_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_f1_weighted = f1_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_auc_weighted = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='weighted')\n",
    "\n",
    "test_precision_macro = precision_score(test_labels_array, test_predictions, average='macro')\n",
    "test_recall_macro = recall_score(test_labels_array, test_predictions, average='macro')\n",
    "test_f1_macro = f1_score(test_labels_array, test_predictions, average='macro')\n",
    "test_auc_macro = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='macro')\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test Weighted Precision: {test_precision_weighted:.4f} - Test Weighted Recall: {test_recall_weighted:.4f} - Test Weighted F1 Score: {test_f1_weighted:.4f} - Test Weighted AUC: {test_auc_weighted:.4f}\")\n",
    "print(f\"Test Macro Precision: {test_precision_macro:.4f} - Test Macro Recall: {test_recall_macro:.4f} - Test Macro F1 Score: {test_f1_macro:.4f} - Test Macro AUC: {test_auc_macro:.4f}\")\n",
    "\n",
    "\n",
    "# Save the results to an Excel file\n",
    "results_dict = {\n",
    "    'Test Loss': [test_loss],\n",
    "    'Test Accuracy': [test_accuracy],\n",
    "    'Test Weighted Precision': [test_precision_weighted],\n",
    "    'Test Weighted Recall': [test_recall_weighted],\n",
    "    'Test Weighted F1 Score': [test_f1_weighted],\n",
    "    'Test Weighted AUC': [test_auc_weighted],\n",
    "    'Test Macro Precision': [test_precision_macro],\n",
    "    'Test Macro Recall': [test_recall_macro],\n",
    "    'Test Macro F1 Score': [test_f1_macro],\n",
    "    'Test Macro AUC': [test_auc_macro],\n",
    "    'Time Dependent Accuracy': [time_dependent_accuracy],\n",
    "    'ATBD': [ATBD_Normalise],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_excel(\"MobileNet_Results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e77f325-05db-4d76-a023-9838f55f31af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.291909282459703"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATBD_Normalise/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc6ee79-eb41-438b-88dd-0a4956b4af72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0104 - Test Accuracy: 0.86%\n",
      "Test Weighted Precision: 0.8656 - Test Weighted Recall: 0.8600 - Test Weighted F1 Score: 0.8597 - Test Weighted AUC: 0.9765\n",
      "Test Macro Precision: 0.8727 - Test Macro Recall: 0.8451 - Test Macro F1 Score: 0.8549 - Test Macro AUC: 0.9784\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sevmou2300\\AppData\\Local\\Temp\\ipykernel_12056\\855736389.py:241: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 241\u001b[0m\n\u001b[0;32m    238\u001b[0m     modified_confusion_df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModified Confusion Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Close the Excel writer\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1275\u001b[0m, in \u001b[0;36mExcelWriter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;124;03mSave workbook to disk.\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m \n\u001b[0;32m   1272\u001b[0m \u001b[38;5;124;03m.. deprecated:: 1.5.0\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:109\u001b[0m, in \u001b[0;36mOpenpyxlWriter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    Save workbook to disk.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, mmap\u001b[38;5;241m.\u001b[39mmmap):\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;66;03m# truncate file to the written content\u001b[39;00m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mtruncate()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\workbook.py:407\u001b[0m, in \u001b[0;36mWorkbook.save\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworksheets:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_sheet()\n\u001b[1;32m--> 407\u001b[0m \u001b[43msave_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openpyxl\\writer\\excel.py:291\u001b[0m, in \u001b[0;36msave_workbook\u001b[1;34m(workbook, filename)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_workbook\u001b[39m(workbook, filename):\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;124;03m\"\"\"Save the given workbook on the filesystem under the name filename.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    :param workbook: the workbook to save\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     archive \u001b[38;5;241m=\u001b[39m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZIP_DEFLATED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowZip64\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ExcelWriter(workbook, archive)\n\u001b[0;32m    293\u001b[0m     writer\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\zipfile.py:1273\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[0;32m   1275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m _Tellable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp)\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Testing phase\n",
    "import numpy as np\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "test_probabilities = []  # Store predicted probabilities instead of class labels\n",
    "test_labels_list = []\n",
    "\n",
    "test_predictions = []\n",
    "test_filenames = []  # List to store filenames\n",
    "\n",
    "# Load your Excel files and extract date information into a dictionary\n",
    "# Replace 'path_to_excel_folder' with the actual path to your Excel files\n",
    "excel_files = ['class_0.xlsx', 'class_1.xlsx', 'class_2.xlsx', 'class_3.xlsx']\n",
    "date_info = {}\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to calculate the time difference between two timestamps\n",
    "def calculate_time_difference(time1, time2):\n",
    "    datetime_format = \"%Y:%m:%d %H:%M:%S\"\n",
    "    t1 = datetime.strptime(time1, datetime_format)\n",
    "    t2 = datetime.strptime(time2, datetime_format)\n",
    "    time_diff = abs((t1 - t2).total_seconds())  # Time difference in seconds\n",
    "    return time_diff\n",
    "\n",
    "# Assuming you have a function to load the creation date from the Excel file\n",
    "def load_creation_date(image_title, excel_file):\n",
    "    try:\n",
    "        # Load the Excel file into a DataFrame\n",
    "        df = pd.read_excel(excel_file)\n",
    "\n",
    "        # Assuming the DataFrame has columns 'Image Title' and 'Creation Date'\n",
    "        if 'Image Title' in df.columns and 'Creation Date' in df.columns:\n",
    "            # Find the row where 'Image Title' matches the given image_title\n",
    "            row = df[df['Image Title'] == image_title]\n",
    "\n",
    "            # Check if a matching row was found\n",
    "            if not row.empty:\n",
    "                # Extract the creation date from the matching row\n",
    "                creation_date = row.iloc[0]['Creation Date']\n",
    "\n",
    "                # Ensure that the creation date is a string\n",
    "                if isinstance(creation_date, str):\n",
    "                    return creation_date\n",
    "\n",
    "        # If the image title was not found or the date is not a string, return None\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading creation date for '{image_title}' from '{excel_file}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "time_boundaries = [\n",
    "    \"2023:05:16 00:00:00\",  # t0\n",
    "    \"2023:05:27 21:13:46\",  # t1\n",
    "    \"2023:06:08 12:03:15\",  # t2\n",
    "    \"2023:06:20 13:51:00\",  # t3\n",
    "    \"2023:06:29 14:32:00\"   # t4\n",
    "]\n",
    "\n",
    "threshold = 21600  # Maximum allowable time difference in seconds (adjust as needed)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_correct_time_dependent = 0  # Counter for time-dependent correct predictions\n",
    "test_total = 0\n",
    " # Initialize total penalty\n",
    "total_penalty = 0\n",
    "ATBD_Todal = 0\n",
    "num_classes = len(time_boundaries) - 1  # Number of classes\n",
    "modified_confusion = [[0.0 for _ in range(num_classes)] for _ in range(num_classes)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        filenames = batch['filename']\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_correct += torch.sum(predictions == labels).item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "        test_probabilities.extend(probabilities.cpu().tolist())\n",
    "        test_labels_list.extend(labels.cpu().tolist())\n",
    "        test_predictions.extend(predictions.cpu().tolist())\n",
    "        test_filenames.extend(filenames)\n",
    "        \n",
    "        # Constants\n",
    "        THRESHOLD = 21600\n",
    "\n",
    "       \n",
    "        for i in range(len(filenames)):\n",
    "            true_class = labels[i].item()\n",
    "            predicted_class = predictions[i].item()\n",
    "            image_title = filenames[i]\n",
    "    \n",
    "            # Check if true class equals predicted class\n",
    "            if true_class == predicted_class:\n",
    "                penalty = 1  # Set penalty to 0\n",
    "                ATBD_Sample = 0  # Set ATBD_Sample to 0\n",
    "                modified_confusion[true_class][true_class] += 1\n",
    "            else:\n",
    "                # Load creation date and calculate time differences\n",
    "                creation_date = load_creation_date(image_title, excel_files[true_class])\n",
    "                lower_bound = time_boundaries[predicted_class]\n",
    "                upper_bound = time_boundaries[predicted_class + 1]\n",
    "                time_diff_lower = calculate_time_difference(creation_date, lower_bound)\n",
    "                time_diff_upper = calculate_time_difference(creation_date, upper_bound)\n",
    "        \n",
    "                # Calculate closeness\n",
    "                time_difference = min(time_diff_lower, time_diff_upper)\n",
    "        \n",
    "                # Calculate penalty\n",
    "                if time_difference <= THRESHOLD:\n",
    "                    penalty = time_difference / THRESHOLD\n",
    "                    # Accumulate the penalty in the modified confusion matrix\n",
    "                    modified_confusion[true_class][predicted_class] += penalty   \n",
    "                else:\n",
    "                    penalty = 0\n",
    "                    # Accumulate the penalty in the modified confusion matrix\n",
    "                    modified_confusion[true_class][predicted_class] += 1 \n",
    "                    \n",
    "                 \n",
    "        \n",
    "                # Calculate ATBD_Sample\n",
    "                ATBD_Sample = max(0, time_difference - THRESHOLD)\n",
    "    \n",
    "            # Accumulate penalties\n",
    "            total_penalty += penalty\n",
    "            # Calculate ATBD_Todal (total penalty)\n",
    "            ATBD_Todal += ATBD_Sample\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the time-dependent accuracy\n",
    "time_dependent_accuracy = total_penalty / test_total\n",
    "ATBD_Normalise=ATBD_Todal/test_total\n",
    "\n",
    "# Calculate the regular accuracy\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# Convert the test_probabilities and test_labels_list to numpy arrays\n",
    "test_probabilities = np.array(test_probabilities)\n",
    "test_labels_array = np.array(test_labels_list)\n",
    "\n",
    "# Calculate testing metrics\n",
    "test_precision_weighted = precision_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_recall_weighted = recall_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_f1_weighted = f1_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_auc_weighted = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='weighted')\n",
    "\n",
    "test_precision_macro = precision_score(test_labels_array, test_predictions, average='macro')\n",
    "test_recall_macro = recall_score(test_labels_array, test_predictions, average='macro')\n",
    "test_f1_macro = f1_score(test_labels_array, test_predictions, average='macro')\n",
    "test_auc_macro = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='macro')\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test Weighted Precision: {test_precision_weighted:.4f} - Test Weighted Recall: {test_recall_weighted:.4f} - Test Weighted F1 Score: {test_f1_weighted:.4f} - Test Weighted AUC: {test_auc_weighted:.4f}\")\n",
    "print(f\"Test Macro Precision: {test_precision_macro:.4f} - Test Macro Recall: {test_recall_macro:.4f} - Test Macro F1 Score: {test_f1_macro:.4f} - Test Macro AUC: {test_auc_macro:.4f}\")\n",
    "\n",
    "\n",
    "# Save the results to an Excel file\n",
    "results_dict = {\n",
    "    'Test Loss': [test_loss],\n",
    "    'Test Accuracy': [test_accuracy],\n",
    "    'Test Weighted Precision': [test_precision_weighted],\n",
    "    'Test Weighted Recall': [test_recall_weighted],\n",
    "    'Test Weighted F1 Score': [test_f1_weighted],\n",
    "    'Test Weighted AUC': [test_auc_weighted],\n",
    "    'Test Macro Precision': [test_precision_macro],\n",
    "    'Test Macro Recall': [test_recall_macro],\n",
    "    'Test Macro F1 Score': [test_f1_macro],\n",
    "    'Test Macro AUC': [test_auc_macro],\n",
    "    'Time Dependent Accuracy': [time_dependent_accuracy],\n",
    "    'ATBD': [ATBD_Normalise],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_excel(\"Mobilenet_Results.xlsx\", index=False)\n",
    "\n",
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(test_labels_array, test_predictions)\n",
    "\n",
    "#Modified CM\n",
    "import matplotlib.pyplot as plt\n",
    "# Assuming 'modified_confusion' is your modified confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(modified_confusion, cmap='viridis', interpolation='nearest')\n",
    "\n",
    "# Add colorbar to the heatmap\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Sum of Penalties')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Modified Confusion Matrix with Penalties')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'confusion' is your confusion matrix and 'modified_confusion' is your modified confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion)\n",
    "modified_confusion_df = pd.DataFrame(modified_confusion)\n",
    "\n",
    "# Create an Excel writer object\n",
    "with pd.ExcelWriter(\"confusion_matrices_mobilenet.xlsx\") as writer:\n",
    "    # Save the confusion matrix to the first tab (sheet)\n",
    "    confusion_df.to_excel(writer, sheet_name=\"Confusion Matrix\", index=False)\n",
    "\n",
    "    # Save the modified confusion matrix to the second tab (sheet)\n",
    "    modified_confusion_df.to_excel(writer, sheet_name=\"Modified Confusion Matrix\", index=False)\n",
    "\n",
    "# Close the Excel writer\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64565d57-1e28-4c09-983e-7184f4732a19",
   "metadata": {},
   "source": [
    "**Test on Top View**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde9ecce-14b0-4b82-bcc3-2f2f8f22ea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_folder = ImageFolder(root=root, transform=transform)\n",
    "        self.classes = self.image_folder.classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_folder[idx]\n",
    "        filename = os.path.basename(self.image_folder.imgs[idx][0])\n",
    "        \n",
    "        return {'image': image, 'label': label, 'filename': filename}\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the labeled dataset using CustomDataset\n",
    "dataset = CustomDataset(root='C:/Users/sevmou2300/Desktop/Home/Postdoc/Task1_Plant_categorisation/Plantvation+Holmen-Spring23/Resizedimage', transform=transform)\n",
    "#test_dataset = dataset\n",
    "# Split the dataset into training and test sets\n",
    "train_size = int(0.2 * len(dataset))  # Adjust the split ratio as needed\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create the pre-trained SqueezeNet model and modify it as a feature extractor\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the MobileNetV2 model so they are not updated during training\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last fully connected layer with a new one that has the correct number of output classes\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.last_channel, num_classes)\n",
    "model = mobilenet.to(device)\n",
    "\n",
    "\n",
    "# Load the state dictionary of the saved model\n",
    "state_dict = torch.load(\"TL_MobileNetV2_Top.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03fc1420-e7ea-4937-8499-2f44c8def8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0264 - Test Accuracy: 0.64%\n",
      "Test Weighted Precision: 0.7007 - Test Weighted Recall: 0.6385 - Test Weighted F1 Score: 0.6228 - Test Weighted AUC: 0.8995\n",
      "Test Macro Precision: 0.7089 - Test Macro Recall: 0.6433 - Test Macro F1 Score: 0.6347 - Test Macro AUC: 0.9080\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Testing phase\n",
    "import numpy as np\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "test_probabilities = []  # Store predicted probabilities instead of class labels\n",
    "test_labels_list = []\n",
    "\n",
    "test_predictions = []\n",
    "test_filenames = []  # List to store filenames\n",
    "\n",
    "# Load your Excel files and extract date information into a dictionary\n",
    "# Replace 'path_to_excel_folder' with the actual path to your Excel files\n",
    "excel_files = ['class_0_Angle.xlsx', 'class_1_Angle.xlsx', 'class_2_Angle.xlsx', 'class_3_Angle.xlsx']\n",
    "date_info = {}\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to calculate the time difference between two timestamps\n",
    "def calculate_time_difference(time1, time2):\n",
    "    datetime_format = \"%Y:%m:%d %H:%M:%S\"\n",
    "    t1 = datetime.strptime(time1, datetime_format)\n",
    "    t2 = datetime.strptime(time2, datetime_format)\n",
    "    time_diff = abs((t1 - t2).total_seconds())  # Time difference in seconds\n",
    "    return time_diff\n",
    "\n",
    "# Assuming you have a function to load the creation date from the Excel file\n",
    "def load_creation_date(image_title, excel_file):\n",
    "    try:\n",
    "        # Load the Excel file into a DataFrame\n",
    "        df = pd.read_excel(excel_file)\n",
    "\n",
    "        # Assuming the DataFrame has columns 'Image Title' and 'Creation Date'\n",
    "        if 'Image Title' in df.columns and 'Creation Date' in df.columns:\n",
    "            # Find the row where 'Image Title' matches the given image_title\n",
    "            row = df[df['Image Title'] == image_title]\n",
    "\n",
    "            # Check if a matching row was found\n",
    "            if not row.empty:\n",
    "                # Extract the creation date from the matching row\n",
    "                creation_date = row.iloc[0]['Creation Date']\n",
    "\n",
    "                # Ensure that the creation date is a string\n",
    "                if isinstance(creation_date, str):\n",
    "                    return creation_date\n",
    "\n",
    "        # If the image title was not found or the date is not a string, return None\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading creation date for '{image_title}' from '{excel_file}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "time_boundaries = [\n",
    "    \"2023:05:16 00:00:00\",  # t0\n",
    "    \"2023:05:27 21:13:46\",  # t1\n",
    "    \"2023:06:08 12:03:15\",  # t2\n",
    "    \"2023:06:20 13:51:00\",  # t3\n",
    "    \"2023:06:29 14:32:00\"   # t4\n",
    "]\n",
    "\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_correct_time_dependent = 0  # Counter for time-dependent correct predictions\n",
    "test_total = 0\n",
    " # Initialize total penalty\n",
    "total_penalty = 0\n",
    "ATBD_Todal = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        filenames = batch['filename']\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_correct += torch.sum(predictions == labels).item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "        test_probabilities.extend(probabilities.cpu().tolist())\n",
    "        test_labels_list.extend(labels.cpu().tolist())\n",
    "        test_predictions.extend(predictions.cpu().tolist())\n",
    "        test_filenames.extend(filenames)\n",
    "        \n",
    "        # Constants\n",
    "        THRESHOLD = 21600\n",
    "\n",
    "       \n",
    "        for i in range(len(filenames)):\n",
    "            true_class = labels[i].item()\n",
    "            predicted_class = predictions[i].item()\n",
    "            image_title = filenames[i]\n",
    "    \n",
    "            # Check if true class equals predicted class\n",
    "            if true_class == predicted_class:\n",
    "                penalty = 1  # Set penalty to 0\n",
    "                ATBD_Sample = 0  # Set ATBD_Sample to 0\n",
    "            else:\n",
    "                # Load creation date and calculate time differences\n",
    "                \n",
    "                creation_date = load_creation_date(image_title, excel_files[true_class])\n",
    "                \n",
    "                lower_bound = time_boundaries[predicted_class]\n",
    "                upper_bound = time_boundaries[predicted_class + 1]\n",
    "                \n",
    "                time_diff_lower = calculate_time_difference(creation_date, lower_bound)\n",
    "                time_diff_upper = calculate_time_difference(creation_date, upper_bound)\n",
    "        \n",
    "                # Calculate closeness\n",
    "                time_difference = min(time_diff_lower, time_diff_upper)\n",
    "        \n",
    "                # Calculate penalty\n",
    "                if time_difference <= THRESHOLD:\n",
    "                    penalty = time_difference / THRESHOLD\n",
    "                else:\n",
    "                    penalty = 0\n",
    "        \n",
    "                # Calculate ATBD_Sample\n",
    "                ATBD_Sample = max(0, time_difference - THRESHOLD)\n",
    "    \n",
    "            # Accumulate penalties\n",
    "            total_penalty += penalty\n",
    "            # Calculate ATBD_Todal (total penalty)\n",
    "            ATBD_Todal += ATBD_Sample\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the time-dependent accuracy\n",
    "time_dependent_accuracy = total_penalty / test_total\n",
    "ATBD_Normalise=ATBD_Todal/test_total\n",
    "\n",
    "# Calculate the regular accuracy\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# Convert the test_probabilities and test_labels_list to numpy arrays\n",
    "test_probabilities = np.array(test_probabilities)\n",
    "test_labels_array = np.array(test_labels_list)\n",
    "\n",
    "# Calculate testing metrics\n",
    "test_precision_weighted = precision_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_recall_weighted = recall_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_f1_weighted = f1_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_auc_weighted = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='weighted')\n",
    "\n",
    "test_precision_macro = precision_score(test_labels_array, test_predictions, average='macro')\n",
    "test_recall_macro = recall_score(test_labels_array, test_predictions, average='macro')\n",
    "test_f1_macro = f1_score(test_labels_array, test_predictions, average='macro')\n",
    "test_auc_macro = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='macro')\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test Weighted Precision: {test_precision_weighted:.4f} - Test Weighted Recall: {test_recall_weighted:.4f} - Test Weighted F1 Score: {test_f1_weighted:.4f} - Test Weighted AUC: {test_auc_weighted:.4f}\")\n",
    "print(f\"Test Macro Precision: {test_precision_macro:.4f} - Test Macro Recall: {test_recall_macro:.4f} - Test Macro F1 Score: {test_f1_macro:.4f} - Test Macro AUC: {test_auc_macro:.4f}\")\n",
    "\n",
    "\n",
    "# Save the results to an Excel file\n",
    "results_dict = {\n",
    "    'Test Loss': [test_loss],\n",
    "    'Test Accuracy': [test_accuracy],\n",
    "    'Test Weighted Precision': [test_precision_weighted],\n",
    "    'Test Weighted Recall': [test_recall_weighted],\n",
    "    'Test Weighted F1 Score': [test_f1_weighted],\n",
    "    'Test Weighted AUC': [test_auc_weighted],\n",
    "    'Test Macro Precision': [test_precision_macro],\n",
    "    'Test Macro Recall': [test_recall_macro],\n",
    "    'Test Macro F1 Score': [test_f1_macro],\n",
    "    'Test Macro AUC': [test_auc_macro],\n",
    "    'Time Dependent Accuracy': [time_dependent_accuracy],\n",
    "    'ATBD': [ATBD_Normalise],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_excel(\"Mobilenet_angle_architucture_0.8.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83652cc2-ff78-4292-a757-bce759c3d2ae",
   "metadata": {},
   "source": [
    "**Sensitivity Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c62f3c8-f63d-42f7-922c-d6debd498c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2919: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "kl_div: Integral inputs not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m    111\u001b[0m _, predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 113\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    115\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:471\u001b[0m, in \u001b[0;36mKLDivLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2931\u001b[0m, in \u001b[0;36mkl_div\u001b[1;34m(input, target, size_average, reduce, reduction, log_target)\u001b[0m\n\u001b[0;32m   2928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2929\u001b[0m         reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m-> 2931\u001b[0m reduced \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2934\u001b[0m     reduced \u001b[38;5;241m=\u001b[39m reduced \u001b[38;5;241m/\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: kl_div: Integral inputs not supported."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the labeled dataset\n",
    "dataset = ImageFolder(root='C:/Users/sevmou2300/Desktop/Home/Postdoc/Task1_Plant_categorisation/Plantvation+Holmen-Spring23/Top camera/ResizedImages', transform=transform)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create the pre-trained MobileNetV2 model and modify it as a feature extractor\n",
    "num_classes = len(dataset.classes)\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the MobileNetV2 model so they are not updated during training\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last fully connected layer with a new one that has the correct number of output classes\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.last_channel, num_classes)\n",
    "model = mobilenet.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#Focal loss \n",
    "#class FocalLoss(nn.Module):\n",
    " #   def __init__(self, gamma=2, alpha=1):\n",
    "#        super(FocalLoss, self).__init__()\n",
    "#        self.gamma = gamma\n",
    "#        self.alpha = alpha\n",
    "\n",
    "#    def forward(self, input, target):\n",
    "#        ce_loss = nn.CrossEntropyLoss(reduction='none')(input, target)\n",
    "#        pt = torch.exp(-ce_loss)\n",
    "#        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "#        return focal_loss.mean()\n",
    "\n",
    "#criterion = FocalLoss()\n",
    "\n",
    "#Label Smoothing loss\n",
    "\n",
    "#class LabelSmoothingLoss(nn.Module):\n",
    "#    def __init__(self, classes, smoothing=0.1):\n",
    "#        super(LabelSmoothingLoss, self).__init__()\n",
    "#        self.classes = classes\n",
    "#        self.smoothing = smoothing\n",
    "\n",
    "#    def forward(self, x, target):\n",
    "#        confidence = 1.0 - self.smoothing\n",
    "#        logprobs = nn.functional.log_softmax(x, dim=-1)\n",
    "#        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "#        nll_loss = nll_loss.squeeze(1)\n",
    "#        smooth_loss = -logprobs.mean()\n",
    "#        loss = (1.0 - confidence) * nll_loss + confidence * smooth_loss\n",
    "#        return loss.mean()\n",
    "\n",
    "#criterion = LabelSmoothingLoss(num_classes, smoothing=0.1)\n",
    "\n",
    "criterion = nn.KLDivLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "# Create some empty arrays to store logs \n",
    "loss_log = []\n",
    "accuracy_log = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += torch.sum(predictions == labels).item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy = 100.0 * train_correct / len(train_loader.dataset)\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f} - Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Store training stats after each epoch\n",
    "    loss_log.append(train_loss)\n",
    "    accuracy_log.append(train_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"TL_MobileNetV2_Top_LabelSmoothingLoss.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8da70f01-7706-44f2-8f2e-b469440deb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_folder = ImageFolder(root=root, transform=transform)\n",
    "        self.classes = self.image_folder.classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_folder[idx]\n",
    "        filename = os.path.basename(self.image_folder.imgs[idx][0])\n",
    "        \n",
    "        return {'image': image, 'label': label, 'filename': filename}\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the labeled dataset using CustomDataset\n",
    "dataset = CustomDataset(root='C:/Users/sevmou2300/Desktop/Home/Postdoc/Task1_Plant_categorisation/Plantvation+Holmen-Spring23/Top camera/ResizedImages', transform=transform)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_size = int(0.2 * len(dataset))  # Adjust the split ratio as needed\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create the pre-trained SqueezeNet model and modify it as a feature extractor\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the MobileNetV2 model so they are not updated during training\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last fully connected layer with a new one that has the correct number of output classes\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.last_channel, num_classes)\n",
    "model = mobilenet.to(device)\n",
    "\n",
    "\n",
    "# Load the state dictionary of the saved model\n",
    "state_dict = torch.load(\"TL_MobileNetV2_Top_LabelSmoothingLoss.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53a44a13-02ba-446a-be8b-37e1fa02794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0381 - Test Accuracy: 0.48%\n",
      "Test Weighted Precision: 0.7440 - Test Weighted Recall: 0.4800 - Test Weighted F1 Score: 0.4137 - Test Weighted AUC: 0.9516\n",
      "Test Macro Precision: 0.7900 - Test Macro Recall: 0.4484 - Test Macro F1 Score: 0.4320 - Test Macro AUC: 0.9577\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Testing phase\n",
    "import numpy as np\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "test_probabilities = []  # Store predicted probabilities instead of class labels\n",
    "test_labels_list = []\n",
    "\n",
    "test_predictions = []\n",
    "test_filenames = []  # List to store filenames\n",
    "\n",
    "# Load your Excel files and extract date information into a dictionary\n",
    "# Replace 'path_to_excel_folder' with the actual path to your Excel files\n",
    "excel_files = ['class_0.xlsx', 'class_1.xlsx', 'class_2.xlsx', 'class_3.xlsx']\n",
    "date_info = {}\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to calculate the time difference between two timestamps\n",
    "def calculate_time_difference(time1, time2):\n",
    "    datetime_format = \"%Y:%m:%d %H:%M:%S\"\n",
    "    t1 = datetime.strptime(time1, datetime_format)\n",
    "    t2 = datetime.strptime(time2, datetime_format)\n",
    "    time_diff = abs((t1 - t2).total_seconds())  # Time difference in seconds\n",
    "    return time_diff\n",
    "\n",
    "# Assuming you have a function to load the creation date from the Excel file\n",
    "def load_creation_date(image_title, excel_file):\n",
    "    try:\n",
    "        # Load the Excel file into a DataFrame\n",
    "        df = pd.read_excel(excel_file)\n",
    "\n",
    "        # Assuming the DataFrame has columns 'Image Title' and 'Creation Date'\n",
    "        if 'Image Title' in df.columns and 'Creation Date' in df.columns:\n",
    "            # Find the row where 'Image Title' matches the given image_title\n",
    "            row = df[df['Image Title'] == image_title]\n",
    "\n",
    "            # Check if a matching row was found\n",
    "            if not row.empty:\n",
    "                # Extract the creation date from the matching row\n",
    "                creation_date = row.iloc[0]['Creation Date']\n",
    "\n",
    "                # Ensure that the creation date is a string\n",
    "                if isinstance(creation_date, str):\n",
    "                    return creation_date\n",
    "\n",
    "        # If the image title was not found or the date is not a string, return None\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading creation date for '{image_title}' from '{excel_file}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "time_boundaries = [\n",
    "    \"2023:05:16 00:00:00\",  # t0\n",
    "    \"2023:05:27 21:13:46\",  # t1\n",
    "    \"2023:06:08 12:03:15\",  # t2\n",
    "    \"2023:06:20 13:51:00\",  # t3\n",
    "    \"2023:06:29 14:32:00\"   # t4\n",
    "]\n",
    "\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_correct_time_dependent = 0  # Counter for time-dependent correct predictions\n",
    "test_total = 0\n",
    " # Initialize total penalty\n",
    "total_penalty = 0\n",
    "ATBD_Todal = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        filenames = batch['filename']\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_correct += torch.sum(predictions == labels).item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "        test_probabilities.extend(probabilities.cpu().tolist())\n",
    "        test_labels_list.extend(labels.cpu().tolist())\n",
    "        test_predictions.extend(predictions.cpu().tolist())\n",
    "        test_filenames.extend(filenames)\n",
    "        \n",
    "        # Constants\n",
    "        THRESHOLD = 21600\n",
    "\n",
    "       \n",
    "        for i in range(len(filenames)):\n",
    "            true_class = labels[i].item()\n",
    "            predicted_class = predictions[i].item()\n",
    "            image_title = filenames[i]\n",
    "    \n",
    "            # Check if true class equals predicted class\n",
    "            if true_class == predicted_class:\n",
    "                penalty = 1  # Set penalty to 0\n",
    "                ATBD_Sample = 0  # Set ATBD_Sample to 0\n",
    "            else:\n",
    "                # Load creation date and calculate time differences\n",
    "                creation_date = load_creation_date(image_title, excel_files[true_class])\n",
    "                lower_bound = time_boundaries[predicted_class]\n",
    "                upper_bound = time_boundaries[predicted_class + 1]\n",
    "                time_diff_lower = calculate_time_difference(creation_date, lower_bound)\n",
    "                time_diff_upper = calculate_time_difference(creation_date, upper_bound)\n",
    "        \n",
    "                # Calculate closeness\n",
    "                time_difference = min(time_diff_lower, time_diff_upper)\n",
    "        \n",
    "                # Calculate penalty\n",
    "                if time_difference <= THRESHOLD:\n",
    "                    penalty = time_difference / THRESHOLD\n",
    "                else:\n",
    "                    penalty = 0\n",
    "        \n",
    "                # Calculate ATBD_Sample\n",
    "                ATBD_Sample = max(0, time_difference - THRESHOLD)\n",
    "    \n",
    "            # Accumulate penalties\n",
    "            total_penalty += penalty\n",
    "            # Calculate ATBD_Todal (total penalty)\n",
    "            ATBD_Todal += ATBD_Sample\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the time-dependent accuracy\n",
    "time_dependent_accuracy = total_penalty / test_total\n",
    "ATBD_Normalise=ATBD_Todal/test_total\n",
    "\n",
    "# Calculate the regular accuracy\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# Convert the test_probabilities and test_labels_list to numpy arrays\n",
    "test_probabilities = np.array(test_probabilities)\n",
    "test_labels_array = np.array(test_labels_list)\n",
    "\n",
    "# Calculate testing metrics\n",
    "test_precision_weighted = precision_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_recall_weighted = recall_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_f1_weighted = f1_score(test_labels_array, test_predictions, average='weighted')\n",
    "test_auc_weighted = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='weighted')\n",
    "\n",
    "test_precision_macro = precision_score(test_labels_array, test_predictions, average='macro')\n",
    "test_recall_macro = recall_score(test_labels_array, test_predictions, average='macro')\n",
    "test_f1_macro = f1_score(test_labels_array, test_predictions, average='macro')\n",
    "test_auc_macro = roc_auc_score(label_binarize(test_labels_array, classes=np.unique(test_labels_array)), test_probabilities, average='macro')\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test Weighted Precision: {test_precision_weighted:.4f} - Test Weighted Recall: {test_recall_weighted:.4f} - Test Weighted F1 Score: {test_f1_weighted:.4f} - Test Weighted AUC: {test_auc_weighted:.4f}\")\n",
    "print(f\"Test Macro Precision: {test_precision_macro:.4f} - Test Macro Recall: {test_recall_macro:.4f} - Test Macro F1 Score: {test_f1_macro:.4f} - Test Macro AUC: {test_auc_macro:.4f}\")\n",
    "\n",
    "\n",
    "# Save the results to an Excel file\n",
    "results_dict = {\n",
    "    'Test Loss': [test_loss],\n",
    "    'Test Accuracy': [test_accuracy],\n",
    "    'Test Weighted Precision': [test_precision_weighted],\n",
    "    'Test Weighted Recall': [test_recall_weighted],\n",
    "    'Test Weighted F1 Score': [test_f1_weighted],\n",
    "    'Test Weighted AUC': [test_auc_weighted],\n",
    "    'Test Macro Precision': [test_precision_macro],\n",
    "    'Test Macro Recall': [test_recall_macro],\n",
    "    'Test Macro F1 Score': [test_f1_macro],\n",
    "    'Test Macro AUC': [test_auc_macro],\n",
    "    'Time Dependent Accuracy': [time_dependent_accuracy],\n",
    "    'ATBD': [ATBD_Normalise],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_excel(\"MobileNet_Result_LabelSmoothingLoss.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170df4cc-c666-4c59-8bb6-9bb12402cabb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
